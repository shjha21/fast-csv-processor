#include <iostream>
#include <fstream>
#include <sstream>
#include <vector>
#include <thread>
#include <mutex>
#include <algorithm>
#include <unordered_map>
#include <future>
#include <curl/curl.h>

using namespace std;

mutex mtx; // Mutex for thread-safe operations

// Structure to hold CSV row data
struct CSVRow {
    vector<string> columns;
};

// Function to read CSV file asynchronously
void readCSV(const string& filename, vector<CSVRow>& data) {
    ifstream file(filename);
    string line;
    while (getline(file, line)) {
        stringstream ss(line);
        string value;
        CSVRow row;
        while (getline(ss, value, ',')) {
            row.columns.push_back(value);
        }
        lock_guard<mutex> lock(mtx);
        data.push_back(row);
    }
}

// Function to sort CSV data by a given column index using parallel sorting
void parallelSortCSV(vector<CSVRow>& data, int columnIndex) {
    vector<thread> threads;
    size_t numThreads = thread::hardware_concurrency();
    size_t chunkSize = data.size() / numThreads;

    vector<vector<CSVRow>> partitions(numThreads);
    for (size_t i = 0; i < numThreads; i++) {
        size_t start = i * chunkSize;
        size_t end = (i == numThreads - 1) ? data.size() : start + chunkSize;
        partitions[i] = vector<CSVRow>(data.begin() + start, data.begin() + end);
        threads.emplace_back([&, i]() {
            sort(partitions[i].begin(), partitions[i].end(), [columnIndex](const CSVRow& a, const CSVRow& b) {
                return a.columns[columnIndex] < b.columns[columnIndex];
            });
        });
    }
    for (auto& t : threads) t.join();
    data.clear();
    for (const auto& part : partitions) {
        data.insert(data.end(), part.begin(), part.end());
    }
}

// Function to filter CSV data based on a column value
vector<CSVRow> filterCSV(const vector<CSVRow>& data, int columnIndex, const string& value) {
    vector<CSVRow> filteredData;
    for (const auto& row : data) {
        if (row.columns[columnIndex] == value) {
            filteredData.push_back(row);
        }
    }
    return filteredData;
}

// Function to aggregate data (count occurrences in a column)
unordered_map<string, int> aggregateCSV(const vector<CSVRow>& data, int columnIndex) {
    unordered_map<string, int> counts;
    for (const auto& row : data) {
        counts[row.columns[columnIndex]]++;
    }
    return counts;
}

// Function to compute minute-wise PCR
unordered_map<string, pair<int, int>> computeMinuteWisePCR(const vector<CSVRow>& data, int timestampIndex, int putIndex, int callIndex) {
    unordered_map<string, pair<int, int>> pcrData;
    for (const auto& row : data) {
        string minute = row.columns[timestampIndex].substr(0, 5);
        pcrData[minute].first += stoi(row.columns[putIndex]);
        pcrData[minute].second += stoi(row.columns[callIndex]);
    }
    return pcrData;
}

// Function to fetch real-time data from an API
size_t writeCallback(void* contents, size_t size, size_t nmemb, string* output) {
    size_t totalSize = size * nmemb;
    output->append((char*)contents, totalSize);
    return totalSize;
}

void fetchRealTimeData(const string& url, vector<CSVRow>& data) {
    CURL* curl = curl_easy_init();
    if (curl) {
        string response;
        curl_easy_setopt(curl, CURLOPT_URL, url.c_str());
        curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, writeCallback);
        curl_easy_setopt(curl, CURLOPT_WRITEDATA, &response);
        CURLcode res = curl_easy_perform(curl);
        if (res == CURLE_OK) {
            stringstream ss(response);
            string line;
            while (getline(ss, line)) {
                stringstream ls(line);
                string value;
                CSVRow row;
                while (getline(ls, value, ',')) {
                    row.columns.push_back(value);
                }
                lock_guard<mutex> lock(mtx);
                data.push_back(row);
            }
        }
        curl_easy_cleanup(curl);
    }
}

// Function to write processed CSV data to a file
void writeCSV(const string& filename, const vector<CSVRow>& data) {
    ofstream file(filename);
    for (const auto& row : data) {
        for (size_t i = 0; i < row.columns.size(); i++) {
            file << row.columns[i];
            if (i < row.columns.size() - 1) file << ",";
        }
        file << endl;
    }
}

int main() {
    vector<CSVRow> data;
    string filename = "example.csv";

    // Fetch real-time data from API (Example URL)
    fetchRealTimeData("https://example.com/realtime.csv", data);

    // Multi-threaded CSV reading
    future<void> readerFuture = async(launch::async, readCSV, filename, ref(data));
    readerFuture.get();

    // Parallel Sorting example
    parallelSortCSV(data, 0);
    
    // Filtering example
    auto filteredData = filterCSV(data, 1, "target_value");
    
    // Aggregation example
    auto aggregatedData = aggregateCSV(data, 2);
    
    // Computing minute-wise PCR
    auto pcrData = computeMinuteWisePCR(data, 0, 2, 3);
    
    // Writing sorted data to a new file
    writeCSV("sorted_output.csv", data);
    
    // Writing filtered data to a new file
    writeCSV("filtered_output.csv", filteredData);
    
    // Printing minute-wise PCR results
    cout << "Minute-wise PCR Calculation:\n";
    for (const auto& entry : pcrData) {
        double pcr = (entry.second.second == 0) ? 0 : (double)entry.second.first / entry.second.second;
        cout << entry.first << ", Put Volume: " << entry.second.first << ", Call Volume: " << entry.second.second << ", PCR: " << pcr << endl;
    }
    
    return 0;
}
